{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a83bf34",
   "metadata": {},
   "source": [
    "### <font color='purple'>Метрики и способы оценки качества модели</font>\n",
    "\n",
    "#### <font color='purple'>Регрессия</font>\n",
    "- Среднеквадратичная ошибка (mean_squared_error, MSE). Это метрика для задач регрессии (когда модель предсказывает непрерывные числа, например, цену или температуру). Она измеряет средний квадрат разницы между реальными значениями и предсказанными моделью.\n",
    "Чем меньше значение, тем лучше модель.\n",
    "    - Плюс: Учитывает большие ошибки сильнее (из-за квадрата).\n",
    "    - Минус: Чувствительна к выбросам, и результат в квадратах единиц (например, если цена в рублях, то ошибка в рублях² — не всегда удобно интерпретировать).\n",
    "- Коэффициент детерминации (r2_score). Для регрессии. Показывает, насколько хорошо модель объясняет разброс данных по сравнению с простой средней. Значение от -∞ до 1: 1 — идеальная модель, 0 — модель не лучше, чем просто среднее значение, отрицательное — модель хуже среднего. Полезна, чтобы понять, сколько процентов вариации данных модель \"захватила\".\n",
    "- Средняя абсолютная ошибка (mean_absolute_error) Для регрессии. Измеряет среднюю абсолютную (по модулю) разницу между реальными и предсказанными значениями. Чем меньше, тем лучше.\n",
    "    - Плюс: Легко понять (в тех же единицах, что и данные, например, рубли).\n",
    "    - Минус: Не наказывает большие ошибки так сильно, как квадратичная.\n",
    "#### <font color='purple'>Классификация</font>\n",
    "- Точность (accuracy_score) Для задач классификации (когда модель делит данные на классы, например, \"спам/не спам\"). Это доля правильных предсказаний от всех. Например, если из 100 примеров модель угадала 90 — точность 0.9 (90%).\n",
    "    - Плюс: Простая и понятная.\n",
    "    - Минус: Плохо работает с несбалансированными классами (если 99% — один класс, модель может просто всегда предсказывать его и получить высокую точность, но быть бесполезной).\n",
    "- Точность класса (precision_score) Для классификации. Измеряет, сколько из предсказанных положительных примеров действительно положительные. Например, если модель сказала \"спам\" 10 раз, а реально спам было 8 — точность класса 0.8. Важна, когда ложные положительные дорогие (например, в медицине: не хочется зря диагностировать болезнь).\n",
    "- Полнота (recall_score) Для классификации. Измеряет, сколько реальных положительных примеров модель нашла. Например, если реально 10 спамов, а модель нашла 8 — полнота 0.8. Важна, когда пропустить положительный — плохо (например, не заметить болезнь). \n",
    "- F1-мера (f1_score) Для классификации. Это среднее между точностью класса и полнотой (гармоническое среднее). Балансирует их: высокая, если обе хорошие.\n",
    "Полезна для несбалансированных данных, когда нужна одна общая метрика.\n",
    "#### <font color='purple'>Кластеризация</font>\n",
    "- Скорректированный индекс Рэнда (ARI, Adjusted Rand Index) Для задач кластеризации (когда модель группирует данные без меток, например, клиентов по поведению). Измеряет, насколько две группировки похожи (например, предсказанная и реальная). Значение от -1 до 1: 1 — идеальное совпадение, 0 — случайное, отрицательное — хуже случайного. Скорректировано на случайные совпадения, чтобы не переоценивать.\n",
    "- Скорректированная взаимная информация (AMI, Adjusted Mutual Information) Для кластеризации. Измеряет, сколько информации одна группировка даёт о другой (взаимная зависимость). Значение от 0 до 1: 1 — полное совпадение, 0 — независимы. Скорректировано на размер кластеров и случайность, лучше работает с разными размерами групп.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864d28cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame([])\n",
    "print(classification_report(y_test, y_pred))\n",
    "pd.crosstab(y_test, y_pred)\n",
    "print(model.score(X_test,y_test)) # тоже что и accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f06ccd5",
   "metadata": {},
   "source": [
    "ROC-кривые\n",
    "\n",
    "Показывают насколько оценка модели лучше, чем случайное угадывание. Чем ближе кривая к левому верхнему углу, тем лучше. Совпадение с углом обозначает переобучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b338344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
