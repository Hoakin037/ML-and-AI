{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a159f801",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\"> Методы улучшения качества модели после начала обработки данных</font>\n",
    "\n",
    "- <font color=\"purple\">Коррекция весов классов.</font> Коррекция весов классов (Adjusting Class Weights) в алгоритмах машинного обучения может помочь в борьбе с неправильной классификацией при работе с «малыми классами». Это повышает чувствительность модели при работе с такими классами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e845f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Прочесть данные из CSV-файла\n",
    "data = pd.read_csv('your_data.csv')\n",
    "\n",
    "# Указать имя столбца, в котором находится целевая переменная\n",
    "target_column = 'target'\n",
    "\n",
    "# Разделить данные на признаки и целевую переменную\n",
    "X = data.drop(target_column, axis=1)\n",
    "y = data[target_column]\n",
    "\n",
    "# Разделить данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ccbf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "\n",
    "# Разделить данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=10)\n",
    "\n",
    "# Вычислить веса классов\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "print(f\"Class weights: {class_weights_dict}\")\n",
    "\n",
    "model = RandomForestClassifier(class_weight=class_weights_dict, random_state=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Сформировать прогноз на наборе тестовых данных\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2293e1",
   "metadata": {},
   "source": [
    "Используя эти методики можно эффективно справляться с несбалансированностью классов. Это позволяет добиться хорошей работы модели в применении ко всем классам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84acbda1",
   "metadata": {},
   "source": [
    "#### <font color=\"purple\">Кросс-валидация и тюнинг гиперпараметров</font> \n",
    "\n",
    "Кросс-валидация (Cross-Validation, перекрёстная проверка) и тюнинг гиперпараметров (Hyperparameter Tuning) — это основные методы, используемые при выборе модели, наилучшим образом подходящей для решения задачи. Их применение помогает избежать переобучения модели. Они позволяют добиться того, чтобы модель, встречаясь с ранее неизвестными ей данными, хорошо работала бы с ними и не теряла бы эффективности.\n",
    "\n",
    "Когда, перед обучением и проверкой модели, данные лишь один раз делят на обучающий и тестовый наборы, это приводит к получению модели, отличающейся высокой дисперсией. На такую модель влияют (сильнее, чем того хотелось бы) отдельные образцы, которые оказываются в обучающем и тестовом наборах данных.\n",
    "- <font color=\"purple\">  Кросс-валидация </font> \n",
    "Кросс-валидация — это методика, используемая для оценки эффективности работы модели путём разбиения данных на несколько подмножеств, или блоков (fold) данных, с последующими обучением и проверкой модели на этих подмножествах.\n",
    "\n",
    "- Чаще всего для кросс-валидации моделей используется метод K-Fold Cross-Validation (K-блочная кросс-валидация). Данные разбивают на K подмножеств, а модель обучают и оценивают K раз. Каждый раз один из блоков используется в качестве тестового набора данных, а оставшиеся (k-1) блоков — в качестве обучающего набора данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2e80c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Инициализировать модель\n",
    "model = RandomForestClassifier(random_state=10)\n",
    "\n",
    "# Выполнить 5-блочную кросс-валидацию\n",
    "cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "\n",
    "# Вывести оценки, полученные в ходе кросс-валидации\n",
    "print(f'Cross-Validation Scores: {cv_scores}')\n",
    "print(f'Mean CV Score: {cv_scores.mean():.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5aea1e",
   "metadata": {},
   "source": [
    "<font color=\"purple\">Тюнинг гиперпараметров</font>\n",
    "\n",
    "Тюнинг гиперпараметров предусматривает нахождение оптимальных гиперпараметров для конкретной модели. Вот две распространённых методики тюнинга:\n",
    "\n",
    "- Поиск по сетке (Grid search) включает в себя полный поиск по выбранной сетке параметров. В большинстве случаев такой поиск требует неоправданно большого объёма вычислительных ресурсов.\n",
    "\n",
    "- Случайный поиск (Randomized search) — в ходе поиска осуществляется случайный выбор значений параметров из заданного распределения."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
